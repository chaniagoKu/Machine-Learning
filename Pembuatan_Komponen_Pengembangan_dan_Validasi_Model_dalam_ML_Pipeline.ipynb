{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCyLzyvfOhr-",
        "outputId": "bad354b9-d712-402f-a220-67d1dabf4486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tfx in /usr/local/lib/python3.10/dist-packages (1.14.0)\n",
            "Requirement already satisfied: ml-pipelines-sdk==1.14.0 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.14.0)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.4.0)\n",
            "Requirement already satisfied: ml-metadata<1.15.0,>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.14.0)\n",
            "Requirement already satisfied: packaging<21,>=20 in /usr/local/lib/python3.10/dist-packages (from tfx) (20.9)\n",
            "Requirement already satisfied: portpicker<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.5.2)\n",
            "Requirement already satisfied: protobuf<5,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tfx) (3.20.3)\n",
            "Requirement already satisfied: docker<5,>=4.1 in /usr/local/lib/python3.10/dist-packages (from tfx) (4.4.4)\n",
            "Requirement already satisfied: google-apitools<1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tfx) (0.5.31)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.12.11)\n",
            "Requirement already satisfied: jinja2<4,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from tfx) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from tfx) (4.5.0)\n",
            "Requirement already satisfied: apache-beam[gcp]<3,>=2.47 in /usr/local/lib/python3.10/dist-packages (from tfx) (2.50.0)\n",
            "Requirement already satisfied: attrs<22,>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from tfx) (21.4.0)\n",
            "Requirement already satisfied: click<9,>=7 in /usr/local/lib/python3.10/dist-packages (from tfx) (8.1.7)\n",
            "Requirement already satisfied: google-api-core<3 in /usr/local/lib/python3.10/dist-packages (from tfx) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2,>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.44.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<3,>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tfx) (2.34.4)\n",
            "Requirement already satisfied: grpcio<2,>=1.28.1 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.62.1)\n",
            "Requirement already satisfied: keras-tuner<2,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.4.7)\n",
            "Requirement already satisfied: kubernetes<13,>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from tfx) (12.0.1)\n",
            "Requirement already satisfied: numpy<2,>=1.16 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.24.3)\n",
            "Requirement already satisfied: pyarrow<11,>=10 in /usr/local/lib/python3.10/dist-packages (from tfx) (10.0.1)\n",
            "Requirement already satisfied: pyyaml<7,>=6 in /usr/local/lib/python3.10/dist-packages (from tfx) (6.0.1)\n",
            "Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tfx) (2.13.1)\n",
            "Requirement already satisfied: tensorflow-hub<0.14,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tfx) (0.13.0)\n",
            "Requirement already satisfied: tensorflow-data-validation<1.15.0,>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-model-analysis<0.46.0,>=0.45.0 in /usr/local/lib/python3.10/dist-packages (from tfx) (0.45.0)\n",
            "Requirement already satisfied: tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15 in /usr/local/lib/python3.10/dist-packages (from tfx) (2.13.1)\n",
            "Requirement already satisfied: tensorflow-transform<1.15.0,>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.14.0)\n",
            "Requirement already satisfied: tfx-bsl<1.15.0,>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.14.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (1.7)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (3.9.15)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (1.9.4)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (0.19)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (0.22.0)\n",
            "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (0.6.1)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (4.6.2)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (1.23.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2023.4)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2023.12.25)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.31.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (0.22.0)\n",
            "Requirement already satisfied: cachetools<6,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (5.3.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (0.1.1)\n",
            "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.15.2)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.20.3)\n",
            "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (1.9.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.24.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.3.3)\n",
            "Requirement already satisfied: google-cloud-bigtable<3,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.22.0)\n",
            "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (3.44.0)\n",
            "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (3.16.0)\n",
            "Requirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.13.3)\n",
            "Requirement already satisfied: google-cloud-videointelligence<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.13.3)\n",
            "Requirement already satisfied: google-cloud-vision<4,>=2 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (3.7.2)\n",
            "Requirement already satisfied: google-cloud-recommendations-ai<0.11.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (0.10.10)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker<5,>=4.1->tfx) (1.16.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<5,>=4.1->tfx) (1.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3->tfx) (1.63.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<2,>=1.8->tfx) (3.0.1)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from google-apitools<1,>=0.5->tfx) (4.1.3)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (2.0.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<3,>=2.26.0->tfx) (2.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4,>=2.7.3->tfx) (2.1.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner<2,>=1.0.4->tfx) (2.13.1)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner<2,>=1.0.4->tfx) (1.0.5)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (2024.2.2)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (67.7.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (1.4.0)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (2.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging<21,>=20->tfx) (3.1.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker<2,>=1.3.1->tfx) (5.9.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (24.3.7)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tfx) (0.36.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-data-validation<1.15.0,>=1.14.0->tfx) (1.3.2)\n",
            "Requirement already satisfied: pandas<2,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-data-validation<1.15.0,>=1.14.0->tfx) (1.5.3)\n",
            "Requirement already satisfied: pyfarmhash<0.4,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-data-validation<1.15.0,>=1.14.0->tfx) (0.3.2)\n",
            "Requirement already satisfied: tensorflow-metadata<1.15,>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-data-validation<1.15.0,>=1.14.0->tfx) (1.14.0)\n",
            "Requirement already satisfied: ipython<8,>=7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (7.7.1)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (9.4.0)\n",
            "Requirement already satisfied: scipy<2,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (1.11.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tfx) (0.43.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3->tfx) (1.48.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx) (4.9)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tfx) (0.13.0)\n",
            "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tfx) (7.7.0)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx) (0.4.4)\n",
            "Requirement already satisfied: deprecated>=1.2.14 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx) (1.2.14)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx) (0.15.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=2.26.0->tfx) (1.5.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (0.6.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (3.0.10)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->tfx) (0.5.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam[gcp]<3,>=2.47->tfx) (2.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tfx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tfx) (3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tfx) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tfx) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tfx) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tfx) (3.0.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx) (3.2.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (6.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.2.13)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (6.5.5)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (5.10.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (1.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (4.17.3)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (21.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.20.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (3.7.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahapan pengembangan dan validasi model ini terdiri dari beberapa proses seperti berikut.\n",
        "\n",
        "- Proses pengembangan model. Pada proses ini menggunakan komponen Trainer.\n",
        "- Proses analisis dan validasi model. Proses ini akan dibuat menggunakan komponen Resolver dan Evaluator."
      ],
      "metadata": {
        "id": "QTL6DF8_QHXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Membuat Tahapan Pengembangan Model"
      ],
      "metadata": {
        "id": "PMuqKARLQIKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Fungsi transformed_name()**\n",
        "\n",
        "  Fungsi ini digunakan untuk mengubah nama fitur yang telah melalui proses transform."
      ],
      "metadata": {
        "id": "Zlw2eVn8QYTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformed_name(key):\n",
        "    \"\"\"Renaming transformed features\"\"\"\n",
        "    return key + \"_xf\""
      ],
      "metadata": {
        "id": "E5LTbTx0O3Y5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Fungsi gzip_reader_fn()**\n",
        "\n",
        "  Ia merupakan fungsi yang digunakan untuk memuat data dalam format TFRecord."
      ],
      "metadata": {
        "id": "8BJ990zCQelQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gzip_reader_fn(filenames):\n",
        "    \"\"\"Loads compressed data\"\"\"\n",
        "    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')"
      ],
      "metadata": {
        "id": "YuySL07LQaxp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Fungsi input_fn()**\n",
        "\n",
        "  Ia digunakan untuk memuat transformed_feature yang dihasilkan oleh komponen Transform dan membaginya ke dalam beberapa batch."
      ],
      "metadata": {
        "id": "NU0iWPtFQmce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "d0VMLICkQguP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_fn(file_pattern,\n",
        "             tf_transform_output,\n",
        "             num_epochs,\n",
        "             batch_size=64)->tf.data.Dataset:\n",
        "    \"\"\"Get post_tranform feature & create batches of data\"\"\"\n",
        "\n",
        "    # Get post_transform feature spec\n",
        "    transform_feature_spec = (\n",
        "        tf_transform_output.transformed_feature_spec().copy())\n",
        "\n",
        "    # create batches of data\n",
        "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "        file_pattern=file_pattern,\n",
        "        batch_size=batch_size,\n",
        "        features=transform_feature_spec,\n",
        "        reader=gzip_reader_fn,\n",
        "        num_epochs=num_epochs,\n",
        "        label_key = transformed_name(LABEL_KEY))\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "vOTOSpGgQrzo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Fungsi model_builder()**\n",
        "\n",
        "  Fungsi inilah yang bertanggung jawab dalam membuat arsitektur model. Pada latihan ini, kita menggunakan salah satu embedding layer yang tersedia dan dapat diunduh melalui TensorFlow Hub\n",
        "\n",
        "  https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/tensorFlow2/variations/universal-sentence-encoder/versions/2?tfhub-redirect=true"
      ],
      "metadata": {
        "id": "EDeAn1ilQ0gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "ZUVRuTOYQu5R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\")\n",
        "embeddings = embed([\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"I am a sentence for which I would like to get its embedding\"])\n",
        "\n",
        "print(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzK7HdsARJUG",
        "outputId": "38bd4aab-2015-4072-ca9d-11e77122cecc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-0.03133017 -0.06338634 -0.01607501 ... -0.03242778 -0.0457574\n",
            "   0.05370456]\n",
            " [ 0.0508086  -0.01652434  0.01573779 ...  0.00976657  0.03170121\n",
            "   0.01788118]], shape=(2, 512), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 10000\n",
        "SEQUENCE_LENGTH = 100\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=SEQUENCE_LENGTH)\n",
        "\n",
        "embedding_layer = hub.KerasLayer(\n",
        "    \"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\",\n",
        "    input_shape=[],  # Input shape is a single sentence\n",
        "    dtype=tf.string,\n",
        "    trainable=False  # Set to True if you want to fine-tune the embedding layer\n",
        ")\n",
        "\n",
        "embedding_dim=16\n",
        "def model_builder():\n",
        "    \"\"\"Build machine learning model\"\"\"\n",
        "    inputs = tf.keras.Input(shape=(1,), name=transformed_name(FEATURE_KEY), dtype=tf.string)\n",
        "    reshaped_narrative = tf.reshape(inputs, [-1])\n",
        "    x = vectorize_layer(reshaped_narrative)\n",
        "    x = layers.Embedding(VOCAB_SIZE, embedding_dim, name=\"embedding\")(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs = outputs)\n",
        "\n",
        "    model.compile(\n",
        "        loss = 'binary_crossentropy',\n",
        "        optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "\n",
        "    )\n",
        "\n",
        "    print(model)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "osAe7o9cQ2ox"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Fungsi _get_serve_tf_examples_fn()**\n",
        "\n",
        "  Fungsi ini digunakan untuk menjalankan tahapan preprocessing data pada raw request data."
      ],
      "metadata": {
        "id": "8blvPS6FTZV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "\n",
        "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "    @tf.function\n",
        "    def serve_tf_examples_fn(serialized_tf_examples):\n",
        "\n",
        "        feature_spec = tf_transform_output.raw_feature_spec()\n",
        "\n",
        "        feature_spec.pop(LABEL_KEY)\n",
        "\n",
        "        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
        "\n",
        "        transformed_features = model.tft_layer(parsed_features)\n",
        "\n",
        "        # get predictions using the transformed features\n",
        "        return model(transformed_features)\n",
        "\n",
        "    return serve_tf_examples_fn"
      ],
      "metadata": {
        "id": "-Rt13a_-Q7eY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Fungsi run_fn()**\n",
        "\n",
        "  Ia merupakan fungsi yang bertanggung jawab untuk menjalankan proses training model sesuai dengan parameter training yang diberikan."
      ],
      "metadata": {
        "id": "nS6ngVxATiz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import NamedTuple\n",
        "import os\n",
        "\n",
        "class FnArgs(NamedTuple):\n",
        "    serving_model_dir: str\n",
        "    transform_graph_path: str\n",
        "    train_files: str\n",
        "    eval_files: str"
      ],
      "metadata": {
        "id": "ihPR40z5T0Mt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_fn(fn_args: FnArgs) -> None:\n",
        "\n",
        "    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), 'logs')\n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir = log_dir, update_freq='batch'\n",
        "    )\n",
        "\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', mode='max', verbose=1, patience=10)\n",
        "    mc = tf.keras.callbacks.ModelCheckpoint(fn_args.serving_model_dir, monitor='val_binary_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "    # Load the transform output\n",
        "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
        "\n",
        "    # Create batches of data\n",
        "    train_set = input_fn(fn_args.train_files, tf_transform_output, 10)\n",
        "    val_set = input_fn(fn_args.eval_files, tf_transform_output, 10)\n",
        "    vectorize_layer.adapt(\n",
        "        [j[0].numpy()[0] for j in [\n",
        "            i[0][transformed_name(FEATURE_KEY)]\n",
        "                for i in list(train_set)]])\n",
        "\n",
        "    # Build the model\n",
        "    model = model_builder()\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x = train_set,\n",
        "            validation_data = val_set,\n",
        "            callbacks = [tensorboard_callback, es, mc],\n",
        "            steps_per_epoch = 1000,\n",
        "            validation_steps= 1000,\n",
        "            epochs=10)\n",
        "    signatures = {\n",
        "        'serving_default':\n",
        "        _get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(\n",
        "                                    tf.TensorSpec(\n",
        "                                    shape=[None],\n",
        "                                    dtype=tf.string,\n",
        "                                    name='examples'))\n",
        "    }\n",
        "    model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)"
      ],
      "metadata": {
        "id": "Zu2v27H2TdKQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seluruh fungsi di atas, akan disatukan ke dalam sebuah module file. Namun, sebelum membuat module file, kita perlu mendefinisikan nama dari module tersebut."
      ],
      "metadata": {
        "id": "wqy0iUaIT5cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINER_MODULE_FILE = \"sarcasm_trainer.py\""
      ],
      "metadata": {
        "id": "P8CHsaEeTpZs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya, buatlah sebuah module dengan kode berikut."
      ],
      "metadata": {
        "id": "DfRYWUD0UHTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# writefile {TRAINER_MODULE_FILE}\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import tensorflow_hub as hub\n",
        "from tfx.components.trainer.fn_args_utils import FnArgs\n",
        "\n",
        "LABEL_KEY = \"is_sarcastic\"\n",
        "FEATURE_KEY = \"headline\"\n",
        "\n",
        "def transformed_name(key):\n",
        "    \"\"\"Renaming transformed features\"\"\"\n",
        "    return key + \"_xf\"\n",
        "\n",
        "def gzip_reader_fn(filenames):\n",
        "    \"\"\"Loads compressed data\"\"\"\n",
        "    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
        "\n",
        "\n",
        "def input_fn(file_pattern,\n",
        "             tf_transform_output,\n",
        "             num_epochs,\n",
        "             batch_size=64)->tf.data.Dataset:\n",
        "    \"\"\"Get post_tranform feature & create batches of data\"\"\"\n",
        "\n",
        "    # Get post_transform feature spec\n",
        "    transform_feature_spec = (\n",
        "        tf_transform_output.transformed_feature_spec().copy())\n",
        "\n",
        "    # create batches of data\n",
        "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "        file_pattern=file_pattern,\n",
        "        batch_size=batch_size,\n",
        "        features=transform_feature_spec,\n",
        "        reader=gzip_reader_fn,\n",
        "        num_epochs=num_epochs,\n",
        "        label_key = transformed_name(LABEL_KEY))\n",
        "    return dataset\n",
        "\n",
        "# os.environ['TFHUB_CACHE_DIR'] = '/hub_chace'\n",
        "# embed = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "# Vocabulary size and number of words in a sequence.\n",
        "VOCAB_SIZE = 10000\n",
        "SEQUENCE_LENGTH = 100\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=SEQUENCE_LENGTH)\n",
        "\n",
        "\n",
        "embedding_dim=16\n",
        "def model_builder():\n",
        "    \"\"\"Build machine learning model\"\"\"\n",
        "    inputs = tf.keras.Input(shape=(1,), name=transformed_name(FEATURE_KEY), dtype=tf.string)\n",
        "    reshaped_narrative = tf.reshape(inputs, [-1])\n",
        "    x = vectorize_layer(reshaped_narrative)\n",
        "    x = layers.Embedding(VOCAB_SIZE, embedding_dim, name=\"embedding\")(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs = outputs)\n",
        "\n",
        "    model.compile(\n",
        "        loss = 'binary_crossentropy',\n",
        "        optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "\n",
        "    )\n",
        "\n",
        "    # print(model)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "\n",
        "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "    @tf.function\n",
        "    def serve_tf_examples_fn(serialized_tf_examples):\n",
        "\n",
        "        feature_spec = tf_transform_output.raw_feature_spec()\n",
        "\n",
        "        feature_spec.pop(LABEL_KEY)\n",
        "\n",
        "        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
        "\n",
        "        transformed_features = model.tft_layer(parsed_features)\n",
        "\n",
        "        # get predictions using the transformed features\n",
        "        return model(transformed_features)\n",
        "\n",
        "    return serve_tf_examples_fn\n",
        "\n",
        "def run_fn(fn_args: FnArgs) -> None:\n",
        "\n",
        "    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), 'logs')\n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir = log_dir, update_freq='batch'\n",
        "    )\n",
        "\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', mode='max', verbose=1, patience=10)\n",
        "    mc = tf.keras.callbacks.ModelCheckpoint(fn_args.serving_model_dir, monitor='val_binary_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "    # Load the transform output\n",
        "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
        "\n",
        "    # Create batches of data\n",
        "    train_set = input_fn(fn_args.train_files, tf_transform_output, 10)\n",
        "    val_set = input_fn(fn_args.eval_files, tf_transform_output, 10)\n",
        "    vectorize_layer.adapt(\n",
        "        [j[0].numpy()[0] for j in [\n",
        "            i[0][transformed_name(FEATURE_KEY)]\n",
        "                for i in list(train_set)]])\n",
        "\n",
        "    # Build the model\n",
        "    model = model_builder()\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x = train_set,\n",
        "            validation_data = val_set,\n",
        "            callbacks = [tensorboard_callback, es, mc],\n",
        "            steps_per_epoch = 1000,\n",
        "            validation_steps= 1000,\n",
        "            epochs=10)\n",
        "    signatures = {\n",
        "        'serving_default':\n",
        "        _get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(\n",
        "                                    tf.TensorSpec(\n",
        "                                    shape=[None],\n",
        "                                    dtype=tf.string,\n",
        "                                    name='examples'))\n",
        "    }\n",
        "    model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)"
      ],
      "metadata": {
        "id": "FCrGBA7lUEPS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas akan menghasilkan sebuah module dengan nama **sarcasm_trainer.py**. Module tersebut mengandung training function beserta beberapa helper function yang telah disebutkan sebelumnya."
      ],
      "metadata": {
        "id": "QP8VA1QxUWNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap selanjutnya adalah mendefinisikan komponen **Trainer()**. Komponen ini akan menerima beberapa input seperti berikut.\n",
        "\n",
        "- **module_file** untuk menerima module file yang mengandung mengandung training function beserta beberapa helper function.\n",
        "- **examples** untuk menerima dataset dari komponen ExampleGen.\n",
        "- **schema** untuk menerima data schema dari komponen SchemaGen.\n",
        "- **tansform_graph** untuk menerima transform graph yang dihasilkan dari komponen Transform.\n",
        "- **train_args** untuk menampung parameter training.\n",
        "- **eval_args** untuk menampung parameter testing atau evaluation."
      ],
      "metadata": {
        "id": "RFRGgTnYUZD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tfx.proto import trainer_pb2\n",
        "from tfx.components.trainer.component import Trainer"
      ],
      "metadata": {
        "id": "TDt0f5ksUm0P"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tfx.proto import trainer_pb2\n",
        "\n",
        "# trainer  = Trainer(\n",
        "#     module_file=os.path.abspath(TRAINER_MODULE_FILE),\n",
        "#     examples = transform.outputs['transformed_examples'],\n",
        "#     transform_graph=transform.outputs['transform_graph'],\n",
        "#     schema=schema_gen.outputs['schema'],\n",
        "#     train_args=trainer_pb2.TrainArgs(splits=['train']),\n",
        "#     eval_args=trainer_pb2.EvalArgs(splits=['eval'])\n",
        "# )\n",
        "# interactive_context.run(trainer)"
      ],
      "metadata": {
        "id": "tG5ywmGyURAI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Membuat Tahapan Analisis dan Validasi Model"
      ],
      "metadata": {
        "id": "3R6ZRdyPVT89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Komponen Resolver**\n",
        "\n",
        "  Untuk melakukan analisis dan validasi model, kita perlu menyediakan sebuah baseline model. Hal ini sangat penting terutama ketika kita memiliki lebih dari satu versi model dan ingin membandingkan dua buah versi model yang berbeda. Untuk melakukannya, kita bisa memanfaatkan komponen **Resolver()**."
      ],
      "metadata": {
        "id": "QGC_YRqjVZ5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tfx.dsl.components.common.resolver import Resolver\n",
        "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import LatestBlessedModelStrategy\n",
        "from tfx.types import Channel\n",
        "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "\n",
        "model_resolver = Resolver(\n",
        "    strategy_class=LatestBlessedModelStrategy,\n",
        "    model=Channel(type=Model),\n",
        "    model_blessing=Channel(type=ModelBlessing)\n",
        ").with_id('Latest_blessed_model_resolver')\n",
        "\n",
        "interactive_context = InteractiveContext()\n",
        "interactive_context.run(model_resolver)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "WwoFflwFUcCN",
        "outputId": "b3962b39-f4e9-4fa1-c5ad-0cb7f279bb30"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:InteractiveContext pipeline_root argument not provided: using temporary directory /tmp/tfx-interactive-2024-03-22T08_55_37.497875-5enzlatl as root for pipeline outputs.\n",
            "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at /tmp/tfx-interactive-2024-03-22T08_55_37.497875-5enzlatl/metadata.sqlite.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExecutionResult(\n",
              "    component_id: Latest_blessed_model_resolver\n",
              "    execution_id: 1\n",
              "    outputs:\n",
              "        model: OutputChannel(artifact_type=Model, producer_component_id=Latest_blessed_model_resolver, output_key=model, additional_properties={}, additional_custom_properties={}, _input_trigger=None\n",
              "        model_blessing: OutputChannel(artifact_type=ModelBlessing, producer_component_id=Latest_blessed_model_resolver, output_key=model_blessing, additional_properties={}, additional_custom_properties={}, _input_trigger=None)"
            ],
            "text/html": [
              "<style>\n",
              ".tfx-object.expanded {\n",
              "  padding: 4px 8px 4px 8px;\n",
              "  background: white;\n",
              "  border: 1px solid #bbbbbb;\n",
              "  box-shadow: 4px 4px 2px rgba(0,0,0,0.05);\n",
              "}\n",
              "html[theme=dark] .tfx-object.expanded {\n",
              "  background: black;\n",
              "}\n",
              ".tfx-object, .tfx-object * {\n",
              "  font-size: 11pt;\n",
              "}\n",
              ".tfx-object > .title {\n",
              "  cursor: pointer;\n",
              "}\n",
              ".tfx-object .expansion-marker {\n",
              "  color: #999999;\n",
              "}\n",
              ".tfx-object.expanded > .title > .expansion-marker:before {\n",
              "  content: '▼';\n",
              "}\n",
              ".tfx-object.collapsed > .title > .expansion-marker:before {\n",
              "  content: '▶';\n",
              "}\n",
              ".tfx-object .class-name {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tfx-object .deemphasize {\n",
              "  opacity: 0.5;\n",
              "}\n",
              ".tfx-object.collapsed > table.attr-table {\n",
              "  display: none;\n",
              "}\n",
              ".tfx-object.expanded > table.attr-table {\n",
              "  display: block;\n",
              "}\n",
              ".tfx-object table.attr-table {\n",
              "  border: 2px solid white;\n",
              "  margin-top: 5px;\n",
              "}\n",
              "html[theme=dark] .tfx-object table.attr-table {\n",
              "  border: 2px solid black;\n",
              "}\n",
              ".tfx-object table.attr-table td.attr-name {\n",
              "  vertical-align: top;\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tfx-object table.attr-table td.attrvalue {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<script>\n",
              "function toggleTfxObject(element) {\n",
              "  var objElement = element.parentElement;\n",
              "  if (objElement.classList.contains('collapsed')) {\n",
              "    objElement.classList.remove('collapsed');\n",
              "    objElement.classList.add('expanded');\n",
              "  } else {\n",
              "    objElement.classList.add('collapsed');\n",
              "    objElement.classList.remove('expanded');\n",
              "  }\n",
              "}\n",
              "</script>\n",
              "<div class=\"tfx-object expanded\"><div class = \"title\" onclick=\"toggleTfxObject(this)\"><span class=\"expansion-marker\"></span><span class=\"class-name\">ExecutionResult</span><span class=\"deemphasize\"> at 0x79a7f8cef3d0</span></div><table class=\"attr-table\"><tr><td class=\"attr-name\">.execution_id</td><td class = \"attrvalue\">1</td></tr><tr><td class=\"attr-name\">.component</td><td class = \"attrvalue\">&lt;tfx.dsl.components.common.resolver.Resolver object at 0x79a7f8cee4d0&gt;</td></tr><tr><td class=\"attr-name\">.component.inputs</td><td class = \"attrvalue\"><table class=\"attr-table\"><tr><td class=\"attr-name\">['model']</td><td class = \"attrvalue\">ResolvedChannel(artifact_type=Model, LatestBlessedModelStrategy(Dict(model=Input(), model_blessing=Input()))[&quot;model&quot;])</td></tr><tr><td class=\"attr-name\">['model_blessing']</td><td class = \"attrvalue\">ResolvedChannel(artifact_type=ModelBlessing, LatestBlessedModelStrategy(Dict(model=Input(), model_blessing=Input()))[&quot;model_blessing&quot;])</td></tr></table></td></tr><tr><td class=\"attr-name\">.component.outputs</td><td class = \"attrvalue\"><table class=\"attr-table\"><tr><td class=\"attr-name\">['model']</td><td class = \"attrvalue\"><style>\n",
              ".tfx-object.expanded {\n",
              "  padding: 4px 8px 4px 8px;\n",
              "  background: white;\n",
              "  border: 1px solid #bbbbbb;\n",
              "  box-shadow: 4px 4px 2px rgba(0,0,0,0.05);\n",
              "}\n",
              "html[theme=dark] .tfx-object.expanded {\n",
              "  background: black;\n",
              "}\n",
              ".tfx-object, .tfx-object * {\n",
              "  font-size: 11pt;\n",
              "}\n",
              ".tfx-object > .title {\n",
              "  cursor: pointer;\n",
              "}\n",
              ".tfx-object .expansion-marker {\n",
              "  color: #999999;\n",
              "}\n",
              ".tfx-object.expanded > .title > .expansion-marker:before {\n",
              "  content: '▼';\n",
              "}\n",
              ".tfx-object.collapsed > .title > .expansion-marker:before {\n",
              "  content: '▶';\n",
              "}\n",
              ".tfx-object .class-name {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tfx-object .deemphasize {\n",
              "  opacity: 0.5;\n",
              "}\n",
              ".tfx-object.collapsed > table.attr-table {\n",
              "  display: none;\n",
              "}\n",
              ".tfx-object.expanded > table.attr-table {\n",
              "  display: block;\n",
              "}\n",
              ".tfx-object table.attr-table {\n",
              "  border: 2px solid white;\n",
              "  margin-top: 5px;\n",
              "}\n",
              "html[theme=dark] .tfx-object table.attr-table {\n",
              "  border: 2px solid black;\n",
              "}\n",
              ".tfx-object table.attr-table td.attr-name {\n",
              "  vertical-align: top;\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tfx-object table.attr-table td.attrvalue {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<script>\n",
              "function toggleTfxObject(element) {\n",
              "  var objElement = element.parentElement;\n",
              "  if (objElement.classList.contains('collapsed')) {\n",
              "    objElement.classList.remove('collapsed');\n",
              "    objElement.classList.add('expanded');\n",
              "  } else {\n",
              "    objElement.classList.add('collapsed');\n",
              "    objElement.classList.remove('expanded');\n",
              "  }\n",
              "}\n",
              "</script>\n",
              "<div class=\"tfx-object collapsed\"><div class = \"title\" onclick=\"toggleTfxObject(this)\"><span class=\"expansion-marker\"></span><span class=\"class-name\">Channel</span> of type <span class=\"class-name\">'Model'</span> (0 artifacts)<span class=\"deemphasize\"> at 0x79a7f8ceecb0</span></div><table class=\"attr-table\"><tr><td class=\"attr-name\">.type_name</td><td class = \"attrvalue\">Model</td></tr><tr><td class=\"attr-name\">._artifacts</td><td class = \"attrvalue\">[]</td></tr></table></div></td></tr><tr><td class=\"attr-name\">['model_blessing']</td><td class = \"attrvalue\"><style>\n",
              ".tfx-object.expanded {\n",
              "  padding: 4px 8px 4px 8px;\n",
              "  background: white;\n",
              "  border: 1px solid #bbbbbb;\n",
              "  box-shadow: 4px 4px 2px rgba(0,0,0,0.05);\n",
              "}\n",
              "html[theme=dark] .tfx-object.expanded {\n",
              "  background: black;\n",
              "}\n",
              ".tfx-object, .tfx-object * {\n",
              "  font-size: 11pt;\n",
              "}\n",
              ".tfx-object > .title {\n",
              "  cursor: pointer;\n",
              "}\n",
              ".tfx-object .expansion-marker {\n",
              "  color: #999999;\n",
              "}\n",
              ".tfx-object.expanded > .title > .expansion-marker:before {\n",
              "  content: '▼';\n",
              "}\n",
              ".tfx-object.collapsed > .title > .expansion-marker:before {\n",
              "  content: '▶';\n",
              "}\n",
              ".tfx-object .class-name {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tfx-object .deemphasize {\n",
              "  opacity: 0.5;\n",
              "}\n",
              ".tfx-object.collapsed > table.attr-table {\n",
              "  display: none;\n",
              "}\n",
              ".tfx-object.expanded > table.attr-table {\n",
              "  display: block;\n",
              "}\n",
              ".tfx-object table.attr-table {\n",
              "  border: 2px solid white;\n",
              "  margin-top: 5px;\n",
              "}\n",
              "html[theme=dark] .tfx-object table.attr-table {\n",
              "  border: 2px solid black;\n",
              "}\n",
              ".tfx-object table.attr-table td.attr-name {\n",
              "  vertical-align: top;\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tfx-object table.attr-table td.attrvalue {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<script>\n",
              "function toggleTfxObject(element) {\n",
              "  var objElement = element.parentElement;\n",
              "  if (objElement.classList.contains('collapsed')) {\n",
              "    objElement.classList.remove('collapsed');\n",
              "    objElement.classList.add('expanded');\n",
              "  } else {\n",
              "    objElement.classList.add('collapsed');\n",
              "    objElement.classList.remove('expanded');\n",
              "  }\n",
              "}\n",
              "</script>\n",
              "<div class=\"tfx-object collapsed\"><div class = \"title\" onclick=\"toggleTfxObject(this)\"><span class=\"expansion-marker\"></span><span class=\"class-name\">Channel</span> of type <span class=\"class-name\">'ModelBlessing'</span> (0 artifacts)<span class=\"deemphasize\"> at 0x79a7f8ceec80</span></div><table class=\"attr-table\"><tr><td class=\"attr-name\">.type_name</td><td class = \"attrvalue\">ModelBlessing</td></tr><tr><td class=\"attr-name\">._artifacts</td><td class = \"attrvalue\">[]</td></tr></table></div></td></tr></table></td></tr></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Komponen Evaluator**\n",
        "\n",
        "  Setelah mendefinisikan komponen Resolver, tahap selanjutnya adalah membuat beberapa konfigurasi untuk mengevaluasi model. Konfigurasi ini dibuat menggunakan library TFMA seperti berikut."
      ],
      "metadata": {
        "id": "mxa8U0cLV77m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[tfma.ModelSpec(label_key='is_sarcastic')],\n",
        "    slicing_specs=[tfma.SlicingSpec()],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(metrics=[\n",
        "\n",
        "            tfma.MetricConfig(class_name='ExampleCount'),\n",
        "            tfma.MetricConfig(class_name='AUC'),\n",
        "            tfma.MetricConfig(class_name='FalsePositives'),\n",
        "            tfma.MetricConfig(class_name='TruePositives'),\n",
        "            tfma.MetricConfig(class_name='FalseNegatives'),\n",
        "            tfma.MetricConfig(class_name='TrueNegatives'),\n",
        "            tfma.MetricConfig(class_name='BinaryAccuracy',\n",
        "                threshold=tfma.MetricThreshold(\n",
        "                    value_threshold=tfma.GenericValueThreshold(\n",
        "                        lower_bound={'value':0.5}),\n",
        "                    change_threshold=tfma.GenericChangeThreshold(\n",
        "                        direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                        absolute={'value':0.0001})\n",
        "                    )\n",
        "            )\n",
        "        ])\n",
        "    ]\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "vPGhnyfkVhvs"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada contoh kode di atas, kita mengatur beberapa konfigurasi seperti metrik untuk mengevaluasi model beserta nilai threshold dari suatu metrik. Selain menentukan metrik, kita juga dapat mengatur pembagian kelompok data berdasarkan fitur tertentu pada parameter slicing_specs. Namun, pada latihan ini, kita tidak membagi data ke dalam kelompok data tertentu karena kasus yang diangkat belum terlalu kompleks.\n"
      ],
      "metadata": {
        "id": "CRbfvTb6WIBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah membuat konfigurasi yang akan digunakan untuk mengevaluasi model, tahap berikutnya adalah mendefinisikan komponen Evaluator. Komponen ini akan menerima beberapa input seperti berikut.\n",
        "- examples untuk menerima dataset dari komponen ExampleGen.\n",
        "\n",
        "- model untuk menerima model yang dihasilkan dari komponen Trainer.\n",
        "\n",
        "- baseline_model untuk menampung baseline model yang disediakan oleh komponen Resolver.\n",
        "\n",
        "- eval_config untuk menerima konfigurasi untuk mengevaluasi model."
      ],
      "metadata": {
        "id": "wD0PHxwvWJqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from tfx.components import Evaluator\n",
        "# evaluator = Evaluator(\n",
        "#     examples=example_gen.outputs['examples'],\n",
        "#     model=trainer.outputs['model'],\n",
        "#     baseline_model=model_resolver.outputs['model'],\n",
        "#     eval_config=eval_config)\n",
        "\n",
        "# interactive_context.run(evaluator)"
      ],
      "metadata": {
        "id": "LJ2YiDt_WCWI"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasil evaluasi dari komponen ini dapat Anda visualisasikan menggunakan library TFMA seperti contoh kode di bawah ini."
      ],
      "metadata": {
        "id": "B3uL-rfmYqr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Visualize the evaluation results\n",
        "# eval_result = evaluator.outputs['evaluation'].get()[0].uri\n",
        "# tfma_result = tfma.load_eval_result(eval_result)\n",
        "# tfma.view.render_slicing_metrics(tfma_result)\n",
        "# tfma.addons.fairness.view.widget_view.render_fairness_indicator(\n",
        "#     tfma_result\n",
        "# )"
      ],
      "metadata": {
        "id": "hC_VQYA9WRGk"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Tools Lanjutan dalam Pengembangan dan Validasi Model**"
      ],
      "metadata": {
        "id": "NBlQoV3SbPTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  # Penjelasan Lanjutan Komponen Tuner"
      ],
      "metadata": {
        "id": "ySAh_iRVbWjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada latihan sebelumnya, kita telah melakukan tahap pengembangan model menggunakan komponen Trainer. Namun, pada latihan tersebut, kita hanya melakukan proses model training dan belum mencakup proses model tuning.\n",
        "\n",
        "Pada TFX pipeline, proses model tuning akan dikerjakan oleh komponen Tuner. Ia akan melakukan proses model tuning secara otomatis dengan bantuan keras tuner. Seperti yang kita bahas pada modul sebelumnya, komponen ini menerima beberapa input seperti berikut.\n",
        "\n",
        "- Data schema yang diperoleh dari tahap data validation.\n",
        "- Transformed data yang diperoleh dari tahap data preprocessing.\n",
        "- Parameter tuning dan training.\n",
        "- Sebuah module file yang berisi *tuner function*."
      ],
      "metadata": {
        "id": "uC9fqdk5bd2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tuner_fn(fn_args):\n",
        "  \"\"\"Build the tuner using the KerasTuner API.\n",
        "  Args:\n",
        "    fn_args: Holds args used to tune models as name/value pairs.\n",
        "\n",
        "  Returns:\n",
        "    A namedtuple contains the following:\n",
        "      - tuner: A BaseTuner that will be used for tuning.\n",
        "      - fit_kwargs: Args to pass to tuner's run_trial function for fitting the\n",
        "                    model , e.g., the training and validation dataset. Required\n",
        "                    args depend on the above tuner's implementation.\n",
        "  \"\"\"\n",
        "  # Memuat training dan validation dataset yang telah di-preprocessing\n",
        "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
        "  train_set = input_fn(fn_args.train_files[0], tf_transform_output)\n",
        "  val_set = input_fn(fn_args.eval_files[0], tf_transform_output)\n",
        "\n",
        "  # Mendefinisikan strategi hyperparameter tuning\n",
        "  tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory=fn_args.working_dir,\n",
        "                     project_name='kt_hyperband')\n",
        "\n",
        "  return TunerFnResult(\n",
        "      tuner=tuner,\n",
        "      fit_kwargs={\n",
        "          \"callbacks\":[stop_early],\n",
        "          'x': train_set,\n",
        "          'validation_data': val_set,\n",
        "          'steps_per_epoch': fn_args.train_steps,\n",
        "          'validation_steps': fn_args.eval_steps\n",
        "      }\n",
        "  )"
      ],
      "metadata": {
        "id": "EZh4rY1pYs-g"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada contoh kode di atas, fungsi **tuner_fn()** menerima sebuah argumen **fn_args**. Argumen ini berisi segala hal yang dibutuhkan untuk menjalankan proses hyperparameter tuning. Sama halnya dengan fungsi run_fn(), fungsi ini juga membutuhkan *helper function*, seperti input_fn() dan model_builder().\n",
        "\n",
        "Setelah membuat module file yang berisi tuner function, tahap selanjutnya adalah mendefinisikan komponen Tuner dan menjalankannya menggunakan **interactive_context()**"
      ],
      "metadata": {
        "id": "V9u9i1uvbw2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tfx.components import Tuner\n",
        "from tfx.proto import trainer_pb2\n",
        "\n",
        "# tuner = Tuner(\n",
        "#     module_file=tuner_module_file,\n",
        "#     examples=transform.outputs['transformed_examples'],\n",
        "#     transform_graph=transform.outputs['transform_graph'],\n",
        "#     schema=schema_gen.outputs['schema'],\n",
        "#     train_args=trainer_pb2.TrainArgs(splits=['train'], num_steps=500),\n",
        "#     eval_args=trainer_pb2.EvalArgs(splits=['eval'], num_steps=100)\n",
        "#     )\n",
        "\n",
        "# interactive_context(tuner)"
      ],
      "metadata": {
        "id": "Zgkoi-DQbrU3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Catatan:**\n",
        "\n",
        "  Kedua kode di atas hanya digunakan sebagai contoh penerapan komponen Tuner dan tidak untuk dijalankan. Anda perlu menghubungkan tuner_fn() dengan module file yang berisi training function. Selain itu, Anda juga perlu menyesuaikan beberapa kode pada **model_builder()** untuk mendukung proses hyperparameter tuning seperti halnya ketika Anda menggunakan Keras Tuner."
      ],
      "metadata": {
        "id": "EE077dorcr0g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jteb8_Lyb8ly"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}